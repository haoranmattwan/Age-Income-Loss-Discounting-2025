{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9c7aa2b",
   "metadata": {},
   "source": [
    "# Replication Code (Python): Age, Income, and the Discounting of Delayed Monetary Losses\n",
    "\n",
    "This Jupyter Notebook provides a complete Python-based replication of the analyses from the publication:\n",
    "\n",
    "> Wan, H., Myerson, J., Green, L., Strube, M. J., & Hale, S. (2025). Age, income, and the discounting of delayed monetary losses. *The Journals of Gerontology, Series B: Psychological Sciences and Social Sciences, 80*(11), gbaf162. https://doi.org/10.1093/geronb/gbaf162\n",
    "\n",
    "The original analysis, conducted in R, has been translated into a Python workflow. This notebook demonstrates proficiency in replicating complex statistical analyses across different programming ecosystems.\n",
    "\n",
    "### Workflow Overview\n",
    "\n",
    "1.  **Setup**: Imports all necessary Python libraries and defines custom functions for modeling and plotting.\n",
    "2.  **Data Processing**: Loads the raw data and cleans it using `pandas`, preparing it for analysis.\n",
    "3.  **Descriptive & Correlational Analyses**: Replicates the paper's descriptive statistics, visualizations (Figure 1), and correlation tables using `matplotlib`, `seaborn`, and `pingouin`.\n",
    "4.  **Hypothesis Testing**: Fits the main Bayesian multilevel beta regression models from the paper (Table 3) using `pymc`.\n",
    "5.  **Supplementary Analyses**: Fits additional models to test the roles of depression and overall distress.\n",
    "6.  **Interaction Plots**: Generates visualizations for the key model interactions (Figure 4), demonstrating the ability to interpret and communicate complex model findings.\n",
    "\n",
    "The data for this study are available in the Supplementary Material at the publisher's website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b9a932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Environment Setup ---\n",
    "# This cell installs all the required Python packages.\n",
    "# It is commented out by default. Uncomment and run this cell if the packages are not yet installed in your environment.\n",
    "\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install pandas numpy scipy statsmodels pymc arviz matplotlib seaborn pingouin patsy jax jaxlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d60a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. SETUP: IMPORTS AND CUSTOM FUNCTIONS ---\n",
    "\n",
    "# --- Core Libraries ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import patsy\n",
    "from scipy.optimize import curve_fit\n",
    "import os\n",
    "import pickle\n",
    "import hashlib\n",
    "\n",
    "# --- Statistics and Modeling ---\n",
    "from sklearn.metrics import r2_score\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import pingouin as pg\n",
    "\n",
    "# --- Visualization ---\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --- Global Settings ---\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "\n",
    "# --- Custom Functions ---\n",
    "\n",
    "def set_plot_theme(ax, title=\"\", xlabel=\"\", ylabel=\"\"):\n",
    "    \"\"\"Applies a consistent, publication-quality theme to a Matplotlib axes object.\"\"\"\n",
    "    ax.set_title(title, fontsize=14, fontweight='bold', pad=15)\n",
    "    ax.set_xlabel(xlabel, fontsize=12, fontweight='bold', labelpad=10)\n",
    "    ax.set_ylabel(ylabel, fontsize=12, fontweight='bold', labelpad=10)\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_edgecolor('black')\n",
    "        spine.set_linewidth(1)\n",
    "    ax.set_facecolor('white')\n",
    "    ax.grid(False)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=10, direction='in')\n",
    "    if ax.get_legend():\n",
    "        ax.legend(frameon=False, title_fontproperties={'weight':'bold', 'size': 12})\n",
    "\n",
    "# Note: We use np.trapz(y, x) for the trapezoidal rule, which is the direct\n",
    "# equivalent of the custom R function.\n",
    "\n",
    "def betaMLM_pymc(formula, data, file=None):\n",
    "    \"\"\"\n",
    "    Fits a Bayesian multilevel beta regression model using PyMC, mirroring brms.\n",
    "\n",
    "    This function uses patsy to parse the model formula, constructs the model in \n",
    "    PyMC with weakly informative priors analogous to the R script, and samples \n",
    "    from the posterior. It includes a file-caching mechanism to avoid re-running.\n",
    "\n",
    "    Args:\n",
    "        formula (str): A patsy-style formula (e.g., \"y ~ x1 + (1|ID)\").\n",
    "                       Random effects are limited to a simple random intercept on ID.\n",
    "        data (pd.DataFrame): The dataframe containing the model variables.\n",
    "        file (str, optional): Path to save/load the fitted model object, \n",
    "                              enabling caching. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        arviz.InferenceData: The fitted model object containing posterior samples.\n",
    "    \"\"\"\n",
    "    if file and os.path.exists(file):\n",
    "        print(f\"Loading cached model from {file}...\")\n",
    "        return az.from_netcdf(file)\n",
    "\n",
    "    coords = {}\n",
    "    if '(1|ID)' in formula:\n",
    "        fixed_formula = formula.partition('(1|ID)')[0].strip().rstrip('+').strip()\n",
    "        has_re = True\n",
    "        id_idx, id_cats = pd.factorize(data['ID'])\n",
    "        coords['ID_dim'] = id_cats\n",
    "    else:\n",
    "        fixed_formula = formula\n",
    "        has_re = False\n",
    "\n",
    "    y_patsy, X_patsy = patsy.dmatrices(fixed_formula, data=data)\n",
    "    y_name = y_patsy.design_info.column_names[0]\n",
    "    y_data = np.asarray(y_patsy).ravel()\n",
    "    X_data = np.asarray(X_patsy)\n",
    "    X_cols = X_patsy.design_info.column_names\n",
    "    \n",
    "    y_data[y_data == 1] = 1 - np.finfo(float).eps\n",
    "    y_data[y_data == 0] = np.finfo(float).eps\n",
    "\n",
    "    with pm.Model(coords=coords) as model:\n",
    "        intercept = pm.Normal('Intercept', mu=0, sigma=1000)\n",
    "        slopes = pm.Cauchy('slopes', alpha=0, beta=2.5, shape=X_data.shape[1] - 1)\n",
    "        betas = pm.math.concatenate([[intercept], slopes])\n",
    "        \n",
    "        nu = pm.HalfNormal('nu', sigma=100)\n",
    "\n",
    "        if has_re:\n",
    "            sigma_id = pm.HalfCauchy('sigma_id', beta=2.5)\n",
    "            z_id = pm.Normal('z_id', mu=0, sigma=1, dims='ID_dim')\n",
    "            intercept_id = pm.Deterministic('intercept_id', z_id * sigma_id, dims='ID_dim')\n",
    "\n",
    "        eta = pm.math.dot(X_data, betas)\n",
    "        if has_re:\n",
    "            eta += intercept_id[id_idx]\n",
    "\n",
    "        mu = pm.math.invlogit(eta)\n",
    "        \n",
    "        # --- THIS IS THE CORRECTED LINE ---\n",
    "        # The parameter is `nu`, not `phi`. The variable holding the prior is now named `nu`.\n",
    "        pm.Beta(y_name, mu=mu, nu=nu, observed=y_data)\n",
    "        \n",
    "        idata = pm.sample(\n",
    "            draws=2000, \n",
    "            tune=2000, \n",
    "            chains=4, \n",
    "            cores=4, \n",
    "            progressbar=True, \n",
    "            target_accept=0.95\n",
    "        )\n",
    "        \n",
    "        idata.posterior = idata.posterior.rename_vars(\n",
    "            {'slopes': [col for col in X_cols if col != 'Intercept']}\n",
    "        )\n",
    "\n",
    "    if file:\n",
    "        print(f\"Saving model to {file}...\")\n",
    "        idata.to_netcdf(file)\n",
    "        \n",
    "    return idata\n",
    "\n",
    "def pymc_summary(idata, rownames=None):\n",
    "    \"\"\"\n",
    "    Creates a formatted summary table from a fitted PyMC model, mirroring brm_summary.\n",
    "\n",
    "    Args:\n",
    "        idata (arviz.InferenceData): The fitted model object.\n",
    "        rownames (list, optional): A list of strings to rename the model parameters \n",
    "                                  in the final output table.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A formatted summary table with posterior medians, standard \n",
    "                      deviations, and probability of direction (pd).\n",
    "    \"\"\"\n",
    "    # 1. Define the statistics to compute: median and standard deviation\n",
    "    stat_funcs = {\n",
    "        \"Est.\": np.median,\n",
    "        \"SE\": np.std\n",
    "    }\n",
    "    \n",
    "    # 2. Get fixed-effect variable names, excluding random effect parameters\n",
    "    var_names = [v for v in idata.posterior.data_vars if v not in \n",
    "                 ['intercept_id', 'z_id', 'sigma_id', 'phi']]\n",
    "    \n",
    "    # 3. Use arviz to calculate summary stats\n",
    "    summary_df = az.summary(\n",
    "        idata, \n",
    "        var_names=var_names, \n",
    "        kind=\"stats\", \n",
    "        stat_funcs=stat_funcs, \n",
    "        extend=False,\n",
    "        sort=False # Keep the original order\n",
    "    )\n",
    "\n",
    "    # 4. Calculate Probability of Direction (pd)\n",
    "    pd_values = []\n",
    "    for var in summary_df.index:\n",
    "        samples = az.extract(idata, var_names=[var])[var].values\n",
    "        pd_val = np.mean(samples > 0)\n",
    "        # Ensure pd is always >= 0.5\n",
    "        pd_values.append(max(pd_val, 1 - pd_val))\n",
    "    summary_df['pd'] = pd_values\n",
    "\n",
    "    # 5. Replicate the specific formatting from the R function\n",
    "    \n",
    "    # Helper for number formatting (remove leading zero)\n",
    "    def format_num(x):\n",
    "        return f\"{x:.3f}\".replace(\"0.\", \".\")\n",
    "\n",
    "    # Format Est. and SE, then combine them\n",
    "    est_formatted = summary_df['Est.'].apply(format_num)\n",
    "    se_formatted = summary_df['SE'].apply(lambda x: f\"({format_num(x)})\")\n",
    "    summary_df[\"Est.(SE)\"] = est_formatted + \" \" + se_formatted\n",
    "    \n",
    "    # Format pd (replace 1.000 with >.999)\n",
    "    def format_pd(x):\n",
    "        if np.isclose(x, 1.0):\n",
    "            return \">.999\"\n",
    "        return format_num(x)\n",
    "    summary_df[\"pd\"] = summary_df[\"pd\"].apply(format_pd)\n",
    "    \n",
    "    # 6. Clean up variable names and finalize the DataFrame\n",
    "    # This mirrors the str_remove_all(..., \"b_|_std|_c\") logic\n",
    "    summary_df.index = summary_df.index.str.replace(\"I(\", \"\", regex=False).str.replace(\" ** 2\", \"^2\", regex=False).str.replace(\")\", \"\", regex=False)\n",
    "    \n",
    "    # Apply custom row names if provided\n",
    "    if rownames:\n",
    "        summary_df.index = rownames\n",
    "\n",
    "    return summary_df[['Est.(SE)', 'pd']]\n",
    "\n",
    "# This is a Python translation of the R power analysis function.\n",
    "# NOTE: It uses statsmodels GLM (not a mixed model) as a frequentist approximation\n",
    "# of glmmTMB, as a direct equivalent for Beta GLMMs is not available.\n",
    "def SimPower_MLM(n_ID, beta1, beta2, nu=12.2, sigma=0.944, n_sim=10):\n",
    "    \"\"\"Simulation-based power analysis for multilevel beta regression.\"\"\"\n",
    "    results = []\n",
    "    print(f\"Running {n_sim} simulations...\")\n",
    "    for i in range(n_sim):\n",
    "        # Data generation logic translated from R\n",
    "        group_ids = np.repeat(np.arange(n_ID * 6), 3)\n",
    "        ages_list = [np.random.uniform(20, 29, n_ID), np.random.uniform(30, 39, n_ID),\n",
    "                     np.random.uniform(40, 49, n_ID), np.random.uniform(50, 59, n_ID),\n",
    "                     np.random.uniform(60, 69, n_ID), np.random.uniform(70, 80, n_ID)]\n",
    "        Age = np.repeat(np.concatenate(ages_list), 3)\n",
    "        Income = np.repeat(np.random.binomial(4, 0.5, n_ID * 6) + 1, 3)\n",
    "        b = np.repeat(np.random.normal(0, sigma, n_ID * 6), 3)\n",
    "        \n",
    "        eta = b + (beta1 / (2 * Age.std())) * Age + (beta2 / (2 * Income.std())) * Income\n",
    "        mu = 1 / (1 + np.exp(-eta))\n",
    "        AuC = np.random.beta(mu * nu, (1 - mu) * nu)\n",
    "        AuC = np.clip(AuC, 1e-9, 1 - 1e-9)\n",
    "        \n",
    "        sim_dat = pd.DataFrame({'ID': group_ids, 'Age': Age, 'Income': Income, 'AuC': AuC})\n",
    "        \n",
    "        # Fit models\n",
    "        try:\n",
    "            dat_20_80 = sim_dat.copy()\n",
    "            dat_20_80['Age_std'] = (dat_20_80['Age'] - dat_20_80['Age'].mean()) / (2 * dat_20_80['Age'].std())\n",
    "            \n",
    "            dat_35_80 = sim_dat[sim_dat['Age'] >= 35].copy()\n",
    "            dat_35_80['Age_std'] = (dat_35_80['Age'] - dat_35_80['Age'].mean()) / (2 * dat_35_80['Age'].std())\n",
    "            dat_35_80['Income_std'] = (dat_35_80['Income'] - dat_35_80['Income'].mean()) / (2 * dat_35_80['Income'].std())\n",
    "            \n",
    "            # Using GLM as approximation of GLMM\n",
    "            fit1 = smf.glm('AuC ~ Age_std', data=dat_20_80, family=sm.families.Binomial()).fit()\n",
    "            fit2 = smf.glm('AuC ~ Age_std + Income_std', data=dat_35_80, family=sm.families.Binomial()).fit()\n",
    "            \n",
    "            results.append([fit1.pvalues['Age_std'], fit2.pvalues['Age_std'], fit2.pvalues['Income_std']])\n",
    "        except:\n",
    "            results.append([np.nan, np.nan, np.nan])\n",
    "            \n",
    "    p_values = pd.DataFrame(results, columns=['p1', 'p2', 'p3'])\n",
    "    power = (p_values < 0.05).mean()\n",
    "    return power.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77f059a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. DATA LOADING AND PROCESSING ---\n",
    "\n",
    "# Load the raw data from the specified sheet in the Excel file\n",
    "Disc_Raw = pd.read_excel(\"Supplementary Data.xlsx\", sheet_name=1)\n",
    "\n",
    "# --- Feature Engineering and Cleaning ---\n",
    "# Create Age_Group factor for plotting\n",
    "age_bins = [19, 34, 50, 64, 80]\n",
    "age_labels = [\"20-34\", \"35-50\", \"51-64\", \"65-80\"]\n",
    "Disc_Raw['age_grp_factor'] = pd.cut(Disc_Raw['Age'], bins=age_bins, labels=age_labels)\n",
    "\n",
    "# Log-transform Amount\n",
    "amount_map = {1: 150, 3: 30000, 2: 2500}\n",
    "Disc_Raw['Amount_log'] = np.log(Disc_Raw['Amount'].map(amount_map))\n",
    "\n",
    "# Ensure correct data types\n",
    "for col in ['Income', 'Education', 'Distress', 'Anxiety', 'Depression']:\n",
    "    Disc_Raw[col] = pd.to_numeric(Disc_Raw[col], errors='coerce')\n",
    "\n",
    "# --- Create Group-Level Dataframe for Plotting ---\n",
    "Disc_Grp = Disc_Raw.copy()\n",
    "Disc_Grp['Amount'] = Disc_Grp['Amount'].map({150: \"$150\", 2500: \"$2,500\", 30000: \"$30,000\"})\n",
    "Disc_Grp['Amount'] = pd.Categorical(Disc_Grp['Amount'], categories=[\"$150\", \"$2,500\", \"$30,000\"], ordered=True)\n",
    "Disc_Grp = Disc_Grp.groupby(['age_grp_factor', 'Amount', 'Delay'], observed=True).agg(Mean_RSV=('RSV', 'mean')).reset_index()\n",
    "\n",
    "# --- Calculate Area under the Curve (AuC) for Each Individual ---\n",
    "AuC_ID = Disc_Raw.sort_values('Delay').groupby(['ID', 'Amount']).apply(\n",
    "    lambda g: np.trapz(y=g['RSV'], x=g['Delay'] / g['Delay'].max())\n",
    ").reset_index(name='AuC')\n",
    "\n",
    "# Join back demographic information\n",
    "demographics = Disc_Raw.drop_duplicates(subset='ID').drop(columns=['Amount', 'Delay', 'RSV', 'Amount_log'])\n",
    "AuC_ID = pd.merge(AuC_ID, demographics, on='ID', how='left')\n",
    "\n",
    "# Clip AuC values for Beta regression\n",
    "AuC_ID['AuC'] = np.clip(AuC_ID['AuC'], 1e-9, 1 - 1e-9)\n",
    "\n",
    "# --- Create Model-Specific Dataframes with Scaled Predictors ---\n",
    "def scale_var(series):\n",
    "    return (series - series.mean()) / (2 * series.std())\n",
    "\n",
    "# Data for Model 1\n",
    "DL_dat1 = AuC_ID[AuC_ID['Age'] >= 35].copy()\n",
    "DL_dat1['Age_std'] = scale_var(DL_dat1['Age'])\n",
    "\n",
    "# Data for Model 2\n",
    "DL_dat2 = AuC_ID[(AuC_ID['Age'] >= 35) & AuC_ID['Income'].notna()].copy()\n",
    "for col in ['Age', 'Income']:\n",
    "    DL_dat2[f'{col}_std'] = scale_var(DL_dat2[col])\n",
    "\n",
    "# Data for Models 3, S1, S3\n",
    "DL_dat3 = AuC_ID[(AuC_ID['Age'] >= 35) & AuC_ID['Income'].notna() & AuC_ID['Distress'].notna()].copy()\n",
    "for col in ['Age', 'Income', 'Anxiety', 'Depression', 'Distress']:\n",
    "    DL_dat3[f'{col}_std'] = scale_var(DL_dat3[col])\n",
    "\n",
    "# Data for Full Models (4, S2, S4)\n",
    "DL_dat4 = AuC_ID[\n",
    "    (AuC_ID['Age'] >= 35) & (AuC_ID['Income'].notna()) & (AuC_ID['Gender'].notna()) &\n",
    "    (AuC_ID['Education'].notna()) & (AuC_ID['Distress'].notna()) & (AuC_ID['Health'].notna())\n",
    "].copy()\n",
    "for col in ['Age', 'Amount', 'Income', 'Education', 'Anxiety', 'Depression', 'Distress', 'Health']:\n",
    "    DL_dat4[f'{col}_std'] = scale_var(DL_dat4[col])\n",
    "DL_dat4['Gender_c'] = DL_dat4['Gender'] - DL_dat4['Gender'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39eee1a",
   "metadata": {},
   "source": [
    "## Descriptive & Correlational Analyses\n",
    "\n",
    "This section replicates the descriptive results from the paper, including the visualization of group-level discounting functions (Figure 1), goodness-of-fit statistics for the hyperboloid model, reliability of the AuC measure, and the correlation matrices for key variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0e02c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. DESCRIPTIVE & CORRELATIONAL ANALYSES ---\n",
    "\n",
    "# --- 4.1 Figure 1 Replication: Group-Level Discounting Functions ---\n",
    "\n",
    "def hyperboloid(delay, k, s):\n",
    "    \"\"\"Mathematical function for hyperboloid discounting.\"\"\"\n",
    "    return 1 / (1 + np.exp(k) * delay)**s\n",
    "\n",
    "# --- Create Plot ---\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 5), sharey=True)\n",
    "colors = {\"$150\": \"#33a02c\", \"$2,500\": \"#ff7f00\", \"$30,000\": \"#1f78b4\"}\n",
    "shapes = {\"$150\": \"s\", \"$2,500\": \"^\", \"$30,000\": \"o\"}\n",
    "linestyles = {\"$150\": \"dotted\", \"$2,500\": \"dashed\", \"$30,000\": \"solid\"}\n",
    "\n",
    "for i, (age_group, group_df) in enumerate(Disc_Grp.groupby('age_grp_factor', observed=True)):\n",
    "    ax = axes[i]\n",
    "    for amount, amount_df in group_df.groupby('Amount', observed=True):\n",
    "        ax.plot(amount_df['Delay'], amount_df['Mean_RSV'], marker=shapes[amount], linestyle='',\n",
    "                color=colors[amount], label=amount, markersize=8, markeredgecolor='black')\n",
    "        \n",
    "        # Fit and plot curve\n",
    "        try:\n",
    "            popt, _ = curve_fit(hyperboloid, amount_df['Delay'], amount_df['Mean_RSV'], p0=[-4, 0.5])\n",
    "            x_pred = np.linspace(-10, 130, 200)\n",
    "            ax.plot(x_pred, hyperboloid(x_pred, *popt), color=colors[amount], linestyle=linestyles[amount], lw=1.5)\n",
    "        except RuntimeError:\n",
    "            print(f\"Curve fit failed for {age_group}, {amount}\")\n",
    "    \n",
    "    set_plot_theme(ax, title=age_group, xlabel=\"Delay (months)\" if i == 0 else \"Delay (months)\")\n",
    "    ax.set_ylim(-0.005, 1.005)\n",
    "    ax.set_xlim(-10, 130)\n",
    "\n",
    "# Add a single legend\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='center right', title='Amount', bbox_to_anchor=(1.0, 0.5))\n",
    "axes[0].set_ylabel(\"Relative Subjective Value\", fontsize=12, fontweight='bold')\n",
    "plt.tight_layout(rect=[0, 0, 0.95, 1])\n",
    "plt.show()\n",
    "\n",
    "# --- Goodness-of-Fit for Group-Level Hyperboloid Functions ---\n",
    "print(\"\\n--- R-squared for Group-Level Hyperboloid Fits ---\")\n",
    "r2_results = Disc_Grp.groupby(['age_grp_factor', 'Amount'], observed=True).apply(\n",
    "    lambda grp: r2_score(grp['Mean_RSV'], hyperboloid(grp['Delay'], *curve_fit(hyperboloid, grp['Delay'], grp['Mean_RSV'], p0=[-4, 0.5])[0]))\n",
    ").unstack()\n",
    "display(r2_results)\n",
    "\n",
    "# --- Test for the \"Amount Effect\" ---\n",
    "print(\"\\n--- P-values for Amount Effect within each Age Group ---\")\n",
    "# analysis for a within-subjects factor within each level of a between-subjects group.\n",
    "amount_effect_pvals = AuC_ID.groupby('age_grp_factor', observed=True).apply(\n",
    "    lambda g: pg.rm_anova(data=g, dv='AuC', within='Amount', subject='ID')['p-unc'][0]\n",
    ").rename('p_value').to_frame()\n",
    "display(amount_effect_pvals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee34aae6",
   "metadata": {},
   "source": [
    "### Reliability and Correlational Analyses\n",
    "\n",
    "This section assesses the internal consistency of the Area under the Curve (AuC) measure across the three different loss amounts. It also replicates the correlation matrices from the paper for both the full sample (ages 20-80) and the primary analysis sample (ages 35-80)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c411316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4.2 Reliability of AuC Measure (Cronbach's Alpha) ---\n",
    "print(\"--- Reliability of AuC Measure (Cronbach's Alpha) ---\")\n",
    "# Pivot the data to have one row per participant and one column per amount\n",
    "reliability_df = AuC_ID.pivot(index='ID', columns='Amount', values='AuC')\n",
    "# Calculate Cronbach's Alpha\n",
    "display(pg.cronbach_alpha(data=reliability_df))\n",
    "\n",
    "# --- 4.3 Correlation Matrix for All Participants (Aged 20-80) ---\n",
    "print(\"\\n--- Correlation Matrix for All Participants (Aged 20-80) ---\")\n",
    "# First, average the repeated measures for each participant\n",
    "Cor_df_full = AuC_ID.groupby('ID').agg({\n",
    "    'Age': 'mean', 'Income': 'mean', 'Education': 'mean', 'Gender': 'mean', \n",
    "    'Distress': 'mean', 'Anxiety': 'mean', 'Depression': 'mean', \n",
    "    'Health': 'mean', 'AuC': 'mean'\n",
    "})\n",
    "# Calculate and display the Pearson correlation matrix\n",
    "display(Cor_df_full.corr(method='pearson').round(3))\n",
    "\n",
    "# --- 4.4 Correlation Matrix for Participants Aged 35-80 (Table 2 Replication) ---\n",
    "print(\"\\n--- Correlation Matrix for Participants Aged 35-80 ---\")\n",
    "# Filter the data to the specified age range, then average and correlate\n",
    "Cor_df_35plus = AuC_ID[AuC_ID['Age'] >= 35].groupby('ID').agg({\n",
    "    'Age': 'mean', 'Income': 'mean', 'Education': 'mean', 'Gender': 'mean', \n",
    "    'Distress': 'mean', 'Anxiety': 'mean', 'Depression': 'mean', \n",
    "    'Health': 'mean', 'AuC': 'mean'\n",
    "})\n",
    "display(Cor_df_35plus.corr(method='pearson').round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89d6ebe",
   "metadata": {},
   "source": [
    "## Hypothesis Testing: Bayesian Multilevel Models\n",
    "\n",
    "This section replicates the main hypothesis tests from the paper, corresponding to Table 3. A series of four Bayesian multilevel beta regression models are fitted to test the effects of age, income, anxiety, and other covariates on AuC for participants aged 35 and older."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de59e4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. HYPOTHESIS TESTING: MAIN MODELS ---\n",
    "\n",
    "# --- Model 1: AuC ~ Age + Age^2 ---\n",
    "# Tests for a linear and quadratic effect of age on discounting.\n",
    "print(\"--- Model 1: AuC ~ Age + Age^2 ---\")\n",
    "idata_mod1b = betaMLM_pymc(\"AuC ~ Age_std + I(Age_std**2) + (1|ID)\", DL_dat1)\n",
    "print(pymc_summary(idata_mod1b))\n",
    "\n",
    "# --- Model 2: AuC ~ Age + Age^2 + Income ---\n",
    "# Adds income as a predictor.\n",
    "print(\"\\n--- Model 2: AuC ~ Age + Age^2 + Income ---\")\n",
    "idata_mod2 = betaMLM_pymc(\"AuC ~ Age_std + I(Age_std**2) + Income_std + (1|ID)\", DL_dat2)\n",
    "print(pymc_summary(idata_mod2))\n",
    "\n",
    "# --- Model 3: AuC ~ Age + Age^2 + Income + Anxiety ---\n",
    "# Adds anxiety as a predictor.\n",
    "print(\"\\n--- Model 3: AuC ~ Age + Age^2 + Income + Anxiety ---\")\n",
    "idata_mod3 = betaMLM_pymc(\"AuC ~ Age_std + I(Age_std**2) + Income_std + Anxiety_std + (1|ID)\", DL_dat3)\n",
    "print(pymc_summary(idata_mod3))\n",
    "\n",
    "# --- Model 4: Full Model with Covariates and Age Interactions ---\n",
    "# The full model includes all covariates and their interactions with age.\n",
    "print(\"\\n--- Model 4: Full Model with Covariates and Age Interactions ---\")\n",
    "formula_mod4 = (\"AuC ~ (Age_std+Income_std + Anxiety_std + Amount_std + Education_std + Gender_c + Health_std)^2 + I(Age_std^2) + (1 + Amount_std|ID))\")\n",
    "idata_mod4 = betaMLM_pymc(formula_mod4, DL_dat4)\n",
    "print(pymc_summary(idata_mod4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c11d67",
   "metadata": {},
   "source": [
    "## Supplementary Analyses: Depression and Distress Models\n",
    "\n",
    "The paper notes that while anxiety was a significant predictor of discounting, depression and overall psychological distress were not (when controlling for age and income). This section presents the models that confirm these findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f72354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. SUPPLEMENTARY ANALYSES: DEPRESSION & DISTRESS ---\n",
    "\n",
    "# --- Model S1: Test effect of Depression ---\n",
    "print(\"--- Model S1: AuC ~ Age + Age^2 + Income + Depression ---\")\n",
    "idata_modS1 = betaMLM_pymc(\"AuC ~ Age_std + I(Age_std**2) + Income_std + Depression_std + (1|ID)\", DL_dat3)\n",
    "print(pymc_summary(idata_modS1))\n",
    "\n",
    "# --- Model S3: Test effect of Distress ---\n",
    "print(\"\\n--- Model S3: AuC ~ Age + Age^2 + Income + Distress ---\\n\")\n",
    "idata_modS3 = betaMLM_pymc(\"AuC ~ Age_std + I(Age_std**2) + Income_std + Distress_std + (1|ID)\", DL_dat3)\n",
    "print(pymc_summary(idata_modS3))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
