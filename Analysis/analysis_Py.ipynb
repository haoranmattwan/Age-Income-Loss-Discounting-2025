{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9c7aa2b",
   "metadata": {},
   "source": [
    "# Age, Income, and the Discounting of Delayed Monetary Losses\n",
    "\n",
    "This notebook replicates the analyses from the publication:\n",
    "\n",
    "> Wan, H., Myerson, J., Green, L., Strube, M. J., & Hale, S. (2025). Age, income, and the discounting of delayed monetary losses. *The Journals of Gerontology, Series B: Psychological Sciences and Social Sciences, 80*(11), gbaf162. https://doi.org/10.1093/geronb/gbaf162\n",
    "\n",
    "The original R analysis is translated into a Python workflow using `pandas`, `statsmodels`, `pymc`, and `matplotlib`/`seaborn`. The analyses examine the effects of age and income on the discounting of delayed monetary losses by fitting a series of Bayesian multilevel beta regressions.\n",
    "\n",
    "The data for this study are available in the Supplementary Material at the publisher's website: <https://doi.org/10.1093/geronb/gbaf162>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b9a932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary packages\n",
    "import sys\n",
    "!{sys.executable} -m pip install pandas numpy scipy statsmodels pymc arviz matplotlib seaborn scikit-learn openpyxl pingouin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "73d60a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Setup: Imports and Custom Functions ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.metrics import auc as calculate_auc, r2_score\n",
    "from scipy.optimize import curve_fit\n",
    "import statsmodels.formula.api as smf\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pingouin as pg\n",
    "import patsy # Import patsy for formula handling\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "\n",
    "def set_mattheme(ax, title=\"\"):\n",
    "    \"\"\"Applies a consistent plot theme.\"\"\"\n",
    "    ax.set_title(title, fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel(ax.get_xlabel(), fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel(ax.get_ylabel(), fontsize=12, fontweight='bold')\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_edgecolor('black')\n",
    "        spine.set_linewidth(1)\n",
    "    ax.set_facecolor('white')\n",
    "    ax.grid(False)\n",
    "\n",
    "# CORRECTED: This version converts patsy objects to NumPy arrays to allow for parallel processing.\n",
    "def betaMLM_pymc(formula, data):\n",
    "    \"\"\"Wrapper to fit a Bayesian beta regression using patsy for formula parsing.\"\"\"\n",
    "    \n",
    "    # 1. Prepare coordinates and formula\n",
    "    coords = {}\n",
    "    if '(1|ID)' in formula:\n",
    "        fixed_formula = formula.split('(1|ID)')[0].strip().rstrip('+').strip()\n",
    "        has_re = True\n",
    "        id_idx, id_cats = pd.factorize(data['ID'])\n",
    "        coords['ID_dim'] = id_cats\n",
    "    else:\n",
    "        fixed_formula = formula\n",
    "        has_re = False\n",
    "\n",
    "    # 2. Use patsy to create design matrices OUTSIDE the model context\n",
    "    y_patsy, X_patsy = patsy.dmatrices(fixed_formula, data=data)\n",
    "    \n",
    "    # 3. Convert patsy objects to simple NumPy arrays (which are picklable)\n",
    "    y_data = np.asarray(y_patsy).ravel()\n",
    "    X_data = np.asarray(X_patsy)\n",
    "    X_cols = X_patsy.design_info.column_names\n",
    "\n",
    "    # 4. Initialize the model with the coordinates\n",
    "    with pm.Model(coords=coords) as model:\n",
    "        # --- Priors ---\n",
    "        intercept = pm.Normal('Intercept', mu=0, sigma=100)\n",
    "        slopes = pm.Cauchy('slopes', alpha=0, beta=2.5, shape=X_data.shape[1] - 1)\n",
    "        betas = pm.math.concatenate([[intercept], slopes])\n",
    "        \n",
    "        if has_re:\n",
    "            sigma_id = pm.HalfCauchy('sigma_id', beta=2.5)\n",
    "            z_id = pm.Normal('z_id', mu=0, sigma=1, dims='ID_dim')\n",
    "            intercept_id = pm.Deterministic('intercept_id', z_id * sigma_id, dims='ID_dim')\n",
    "        \n",
    "        nu = pm.HalfNormal('nu', sigma=100)\n",
    "\n",
    "        # --- Linear Model (eta) ---\n",
    "        # Use the NumPy array X_data here\n",
    "        eta = pm.math.dot(X_data, betas)\n",
    "        if has_re:\n",
    "            eta += intercept_id[id_idx]\n",
    "\n",
    "        # --- Likelihood ---\n",
    "        mu = pm.math.invlogit(eta)\n",
    "        pm.Beta(y_patsy.design_info.column_names[0], mu=mu, nu=nu, observed=y_data)\n",
    "        \n",
    "        # --- Sampling ---\n",
    "        idata = pm.sample(draws=2000, tune=2000, chains=4, cores=4,\n",
    "                          progressbar=False, random_seed=42)\n",
    "        \n",
    "        # Rename variables for easier summary\n",
    "        idata.posterior = idata.posterior.rename_vars(\n",
    "            {'slopes': [col for col in X_cols if col != 'Intercept']}\n",
    "        )\n",
    "    return idata\n",
    "\n",
    "\n",
    "def pymc_summary(idata, var_names=None):\n",
    "    \"\"\"Custom function to format PyMC model summary.\"\"\"\n",
    "    if var_names is None:\n",
    "        # Auto-detect variable names, excluding random effects infrastructure\n",
    "        var_names = [v for v in idata.posterior.data_vars if 'z_id' not in v and 'sigma_id' not in v]\n",
    "\n",
    "    summary = az.summary(idata, var_names=var_names, kind='stats', hdi_prob=0.95)\n",
    "    posterior = az.extract(idata, var_names=var_names)\n",
    "    \n",
    "    pd_values = {}\n",
    "    for var in posterior.data_vars:\n",
    "        samples = posterior[var].values.flatten()\n",
    "        pd = np.mean(samples > 0)\n",
    "        pd = max(pd, 1 - pd)\n",
    "        pd_values[var] = pd\n",
    "        \n",
    "    summary['pd'] = summary.index.map(pd_values)\n",
    "    summary['signif'] = np.where(summary['pd'] >= 0.975, '*', ' ')\n",
    "    summary = summary[['mean', 'sd', 'pd', 'signif']]\n",
    "    summary.columns = ['Est.', '(SE)', 'pd', 'signif']\n",
    "    summary['Est.(SE)'] = summary.apply(lambda row: f\"{row['Est.']:.3f} ({row['(SE)']:.3f})\", axis=1)\n",
    "    \n",
    "    return summary[['Est.(SE)', 'pd', 'signif']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f77f059a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processing complete.\n"
     ]
    }
   ],
   "source": [
    "# --- Data Loading and Processing ---\n",
    "# Load raw data from the main source file\n",
    "Samp = pd.read_csv(\"R code/dat/Lifespan.csv\", index_col=0)\n",
    "\n",
    "# Perform initial filtering and cleaning, matching the R script\n",
    "Disc_Raw = Samp[\n",
    "    (Samp['type'] == 'delay') & (Samp['task'] == 'loss') &\n",
    "    (Samp['age'].notna()) & (Samp['age'].between(20, 80)) &\n",
    "    (Samp['check'] == 6) & (Samp['sex'].notna()) &\n",
    "    ((Samp['age'] - 10 * Samp['age_grp']).between(0, 10))\n",
    "].copy()\n",
    "\n",
    "# Create Age_Group factor\n",
    "age_bins = [19, 34, 50, 64, 80]\n",
    "age_labels = [\"20-34\", \"35-50\", \"51-64\", \"65-80\"]\n",
    "Disc_Raw['age_grp_factor'] = pd.cut(Disc_Raw['age'], bins=age_bins, labels=age_labels)\n",
    "\n",
    "# Rename columns to match the analysis script's expectations\n",
    "rename_dict = {\n",
    "    'type': 'Exp', 'id': 'ID', 'amt': 'Amount', 'iv': 'Delay', 'value': 'SV', 'age': 'Age',\n",
    "    'income': 'Income', 'sex': 'Gender', 'depress': 'Depression', 'anxious': 'Anxiety',\n",
    "    'hads': 'Distress', 'edu': 'Education', 'health': 'Health', 'age_grp_factor': 'Age_Group',\n",
    "    'eth': 'Ethnicity', 'race': 'Race'\n",
    "}\n",
    "Disc_Raw = Disc_Raw.rename(columns=rename_dict)\n",
    "Disc_Raw = Disc_Raw.filter(items=rename_dict.values()) # Keep only renamed columns\n",
    "\n",
    "# Group-Level Data Frame for Plotting\n",
    "Disc_Grp = Disc_Raw.copy()\n",
    "Disc_Grp['Amount'] = pd.Categorical(\n",
    "    Disc_Grp['Amount'].replace({1: \"$150\", 2: \"$2,500\", 3: \"$30,000\"}),\n",
    "    categories=[\"$150\", \"$2,500\", \"$30,000\"], ordered=True\n",
    ")\n",
    "Disc_Grp = Disc_Grp.groupby(['Age_Group', 'Amount', 'Delay'], observed=True).agg(Mean_SV=('SV', 'mean')).reset_index()\n",
    "\n",
    "# Calculate Area under the Curve (AuC) for each individual\n",
    "AuC_ID = Disc_Raw.sort_values('Delay').groupby(['ID', 'Amount']).apply(\n",
    "    lambda g: calculate_auc(g['Delay'] / g['Delay'].max(), g['SV'])\n",
    ").reset_index(name='AuC')\n",
    "\n",
    "# Join back demographic info\n",
    "demographics = Disc_Raw.drop_duplicates(subset='ID').drop(columns=['Amount', 'Delay', 'SV', 'Exp'])\n",
    "AuC_ID = pd.merge(AuC_ID, demographics, on='ID', how='left')\n",
    "\n",
    "# Remap Education codes\n",
    "edu_map = {1: 5, 2: 12, 3: 14, 4: 16, 5: 18}\n",
    "AuC_ID['Education'] = AuC_ID['Education'].map(edu_map)\n",
    "\n",
    "\n",
    "# Create Model-Specific Dataframes with Scaled Predictors\n",
    "def scale_var(series):\n",
    "    return (series - series.mean()) / (2 * series.std())\n",
    "\n",
    "DL_dat0 = AuC_ID.copy()\n",
    "DL_dat0['Age_std'] = scale_var(DL_dat0['Age'])\n",
    "\n",
    "DL_dat1 = AuC_ID[AuC_ID['Age'] >= 35].copy()\n",
    "DL_dat1['Age_std'] = scale_var(DL_dat1['Age'])\n",
    "\n",
    "DL_dat2 = AuC_ID[(AuC_ID['Age'] >= 35) & AuC_ID['Income'].notna()].copy()\n",
    "DL_dat2['Age_std'] = scale_var(DL_dat2['Age'])\n",
    "DL_dat2['Income_std'] = scale_var(DL_dat2['Income'])\n",
    "\n",
    "DL_dat3 = AuC_ID[(AuC_ID['Age'] >= 35) & AuC_ID['Income'].notna() & AuC_ID['Distress'].notna()].copy()\n",
    "DL_dat3['Age_std'] = scale_var(DL_dat3['Age'])\n",
    "DL_dat3['Income_std'] = scale_var(DL_dat3['Income'])\n",
    "DL_dat3['Anxiety_std'] = scale_var(DL_dat3['Anxiety'])\n",
    "\n",
    "DL_dat4 = AuC_ID[\n",
    "    (AuC_ID['Age'] >= 35) & AuC_ID['Income'].notna() & AuC_ID['Gender'].notna() & \n",
    "    AuC_ID['Education'].notna() & AuC_ID['Distress'].notna() & AuC_ID['Health'].notna()\n",
    "].copy()\n",
    "for col in ['Age', 'Amount', 'Income', 'Education', 'Anxiety', 'Health']:\n",
    "    DL_dat4[f'{col}_std'] = scale_var(DL_dat4[col])\n",
    "DL_dat4['Gender_c'] = DL_dat4['Gender'] - DL_dat4['Gender'].mean()\n",
    "\n",
    "# Clip AuC values for Beta regression (must be in the open interval (0, 1))\n",
    "for df in [DL_dat0, DL_dat1, DL_dat2, DL_dat3, DL_dat4]:\n",
    "    df['AuC'] = np.clip(df['AuC'], 1e-5, 1 - 1e-5)\n",
    "\n",
    "print(\"Data processing complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39eee1a",
   "metadata": {},
   "source": [
    "---\n",
    "## Group-Level Descriptive Analyses\n",
    "\n",
    "This section visualizes the group-level discounting functions, reports the goodness-of-fit (R-squared) for the hyperboloid model, and tests for the amount effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b0e02c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- R-squared for Group-Level Hyperboloid Fits ---\n",
      "Amount     $150  $2,500  $30,000\n",
      "Age_Group                       \n",
      "20-34     0.956   0.983    0.997\n",
      "35-50     0.973   0.976    0.965\n",
      "51-64     0.898   0.878    0.955\n",
      "65-80     0.925   0.926    0.890\n"
     ]
    }
   ],
   "source": [
    "# --- Group-Level Analysis: Plot and R2 ---\n",
    "def hyperboloid(delay, k, s):\n",
    "    return 1 / (1 + k * delay)**s\n",
    "\n",
    "# R-squared for group fits\n",
    "print(\"--- R-squared for Group-Level Hyperboloid Fits ---\")\n",
    "r2_results = Disc_Grp.groupby(['Age_Group', 'Amount'], observed=True).apply(\n",
    "    lambda g: r2_score(g['Mean_SV'], hyperboloid(g['Delay'], *curve_fit(hyperboloid, g['Delay'], g['Mean_SV'], p0=[0.1, 1])[0]))\n",
    ").unstack()\n",
    "print(r2_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee34aae6",
   "metadata": {},
   "source": [
    "---\n",
    "## Reliability and Correlational Analyses\n",
    "\n",
    "This section examines the internal consistency of the AuC measure across different amounts and presents the correlation matrix for all key variables for participants aged 35 and older."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c411316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Reliability of AuC Measure (Cronbach's Alpha) ---\n",
      "(np.float64(0.8601565041438437), array([0.839, 0.879]))\n",
      "\n",
      "--- Correlation Matrix for Participants Aged 35-80 ---\n",
      "              Age  Income  Education  Gender  Distress  Anxiety  Depression  \\\n",
      "Age         1.000  -0.031      0.011  -0.029    -0.281   -0.325      -0.174   \n",
      "Income     -0.031   1.000      0.388  -0.132    -0.207   -0.193      -0.177   \n",
      "Education   0.011   0.388      1.000  -0.100    -0.189   -0.171      -0.173   \n",
      "Gender     -0.029  -0.132     -0.100   1.000     0.153    0.174       0.095   \n",
      "Distress   -0.281  -0.207     -0.189   0.153     1.000    0.932       0.893   \n",
      "Anxiety    -0.325  -0.193     -0.171   0.174     0.932    1.000       0.670   \n",
      "Depression -0.174  -0.177     -0.173   0.095     0.893    0.670       1.000   \n",
      "Health      0.026   0.286      0.224  -0.036    -0.515   -0.411      -0.540   \n",
      "AuC         0.206   0.114      0.017  -0.045    -0.149   -0.169      -0.084   \n",
      "\n",
      "            Health    AuC  \n",
      "Age          0.026  0.206  \n",
      "Income       0.286  0.114  \n",
      "Education    0.224  0.017  \n",
      "Gender      -0.036 -0.045  \n",
      "Distress    -0.515 -0.149  \n",
      "Anxiety     -0.411 -0.169  \n",
      "Depression  -0.540 -0.084  \n",
      "Health       1.000  0.096  \n",
      "AuC          0.096  1.000  \n"
     ]
    }
   ],
   "source": [
    "# --- Reliability and Correlations ---\n",
    "print(\"--- Reliability of AuC Measure (Cronbach's Alpha) ---\")\n",
    "reliability_df = AuC_ID.pivot(index='ID', columns='Amount', values='AuC')\n",
    "print(pg.cronbach_alpha(data=reliability_df))\n",
    "\n",
    "print(\"\\n--- Correlation Matrix for Participants Aged 35-80 ---\")\n",
    "Cor_df = AuC_ID[AuC_ID['Age'] >= 35].groupby('ID').agg(\n",
    "    Age=('Age', 'mean'), Income=('Income', 'mean'), Education=('Education', 'mean'),\n",
    "    Gender=('Gender', 'mean'), Distress=('Distress', 'mean'), Anxiety=('Anxiety', 'mean'),\n",
    "    Depression=('Depression', 'mean'), Health=('Health', 'mean'), AuC=('AuC', 'mean')\n",
    ")\n",
    "print(Cor_df.corr(method='pearson').round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89d6ebe",
   "metadata": {},
   "source": [
    "---\n",
    "## Hypothesis Testing: Bayesian Multilevel Models\n",
    "\n",
    "This section presents the results from a series of Bayesian multilevel beta regressions testing the effects of age, income, and other covariates on the discounting of delayed losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de59e4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model 1: AuC ~ Age + Age^2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [Intercept, slopes, sigma_id, z_id, nu]\n"
     ]
    }
   ],
   "source": [
    "# --- Hypothesis Testing: Main Models ---\n",
    "# Model 1: AuC ~ Age\n",
    "print(\"--- Model 1: AuC ~ Age + Age^2 ---\")\n",
    "idata_mod1b = betaMLM_pymc(\"AuC ~ Age_std + I(Age_std**2) + (1|ID)\", DL_dat1)\n",
    "print(pymc_summary(idata_mod1b, ['Intercept', 'Age_std', 'I(Age_std ** 2)']))\n",
    "\n",
    "# Model 2: AuC ~ Age + Income\n",
    "print(\"\\n--- Model 2: AuC ~ Age + Age^2 + Income ---\")\n",
    "idata_mod2 = betaMLM_pymc(\"AuC ~ Age_std + I(Age_std**2) + Income_std + (1|ID)\", DL_dat2)\n",
    "print(pymc_summary(idata_mod2, ['Intercept', 'Age_std', 'I(Age_std ** 2)', 'Income_std']))\n",
    "\n",
    "# Model 3: AuC ~ Age + Income + Anxiety\n",
    "print(\"\\n--- Model 3: AuC ~ Age + Age^2 + Income + Anxiety ---\")\n",
    "idata_mod3 = betaMLM_pymc(\"AuC ~ Age_std + I(Age_std**2) + Income_std + Anxiety_std + (1|ID)\", DL_dat3)\n",
    "print(pymc_summary(idata_mod3, ['Intercept', 'Age_std', 'I(Age_std ** 2)', 'Income_std', 'Anxiety_std']))\n",
    "\n",
    "# Model 4: Full Model with Interactions\n",
    "print(\"\\n--- Model 4: Full Model with Covariates and Age Interactions ---\")\n",
    "formula_mod4 = (\"AuC ~ Age_std * Income_std + Age_std * Anxiety_std + Age_std * Amount_std + \"\n",
    "                \"Age_std * Education_std + Age_std * Gender_c + Age_std * Health_std + \"\n",
    "                \"I(Age_std**2) + (1|ID)\")\n",
    "idata_mod4 = betaMLM_pymc(formula_mod4, DL_dat4)\n",
    "print(pymc_summary(idata_mod4, [v for v in idata_mod4.posterior.data_vars if 'ID' not in v]))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
