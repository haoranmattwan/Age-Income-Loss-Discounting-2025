{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9c7aa2b",
   "metadata": {},
   "source": [
    "# Replication Code (Python): Age, Income, and the Discounting of Delayed Monetary Losses\n",
    "\n",
    "This Jupyter Notebook provides a complete Python-based replication of the analyses from the publication:\n",
    "\n",
    "> Wan, H., Myerson, J., Green, L., Strube, M. J., & Hale, S. (2025). Age, income, and the discounting of delayed monetary losses. *The Journals of Gerontology, Series B: Psychological Sciences and Social Sciences, 80*(11), gbaf162. https://doi.org/10.1093/geronb/gbaf162\n",
    "\n",
    "The original analysis, conducted in R, has been translated into a Python workflow. This notebook demonstrates proficiency in replicating complex statistical analyses across different programming ecosystems.\n",
    "\n",
    "### Workflow Overview\n",
    "\n",
    "1.  **Setup**: Imports all necessary Python libraries and defines custom functions for modeling and plotting.\n",
    "2.  **Data Processing**: Loads the raw data and cleans it using `pandas`, preparing it for analysis.\n",
    "3.  **Descriptive & Correlational Analyses**: Replicates the paper's descriptive statistics, visualizations (Figure 1), and correlation tables using `matplotlib`, `seaborn`, and `pingouin`.\n",
    "4.  **Hypothesis Testing**: Fits the main Bayesian multilevel beta regression models from the paper (Table 3) using `pymc`.\n",
    "5.  **Supplementary Analyses**: Fits additional models to test the roles of depression and overall distress.\n",
    "6.  **Interaction Plots**: Generates visualizations for the key model interactions (Figure 4), demonstrating the ability to interpret and communicate complex model findings.\n",
    "\n",
    "The data for this study are available in the Supplementary Material at the publisher's website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b9a932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Environment Setup ---\n",
    "# This cell installs all the required Python packages.\n",
    "# It is commented out by default. Uncomment and run this cell if the packages are not yet installed in your environment.\n",
    "\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install pandas numpy scipy statsmodels pymc arviz matplotlib seaborn pingouin patsy jax jaxlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d60a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Imports and Custom Functions ---\n",
    "\n",
    "# --- Core Libraries ---\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import patsy\n",
    "\n",
    "\n",
    "# --- Statistics and Modeling ---\n",
    "from sklearn.metrics import auc as calculate_auc, r2_score\n",
    "from scipy.optimize import curve_fit\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import pingouin as pg\n",
    "\n",
    "# --- Visualization ---\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --- Global Settings ---\n",
    "# Suppress warnings for a cleaner notebook output\n",
    "warnings.filterwarnings('ignore')\n",
    "# Set a consistent plotting style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "# Standardize float display format\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "\n",
    "\n",
    "def set_mattheme(ax, title=\"\", xlabel=\"\", ylabel=\"\"):\n",
    "    \"\"\"\n",
    "    Applies a consistent, publication-quality theme to a Matplotlib axes object.\n",
    "    \n",
    "    Args:\n",
    "        ax (matplotlib.axes.Axes): The axes object to style.\n",
    "        title (str): The title for the plot.\n",
    "        xlabel (str): The label for the x-axis.\n",
    "        ylabel (str): The label for the y-axis.\n",
    "    \"\"\"\n",
    "    ax.set_title(title, fontsize=14, fontweight='bold', pad=15)\n",
    "    ax.set_xlabel(xlabel, fontsize=12, fontweight='bold', labelpad=10)\n",
    "    ax.set_ylabel(ylabel, fontsize=12, fontweight='bold', labelpad=10)\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_edgecolor('black')\n",
    "        spine.set_linewidth(1)\n",
    "    ax.set_facecolor('white')\n",
    "    ax.grid(False)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=10, direction='out', width=1, length=5)\n",
    "    ax.legend(frameon=False)\n",
    "\n",
    "\n",
    "# --- betaMLM_pymc function ---\n",
    "def betaMLM_pymc(formula, data):\n",
    "    \"\"\"\n",
    "    Fits a Bayesian multilevel beta regression model using PyMC.\n",
    "\n",
    "    This function uses `patsy` to parse the model formula, constructs the\n",
    "    model in PyMC with weakly informative priors, and samples from the posterior.\n",
    "\n",
    "    Args:\n",
    "        formula (str): A patsy-style formula for the model (e.g., \"y ~ x1 + (1|group)\").\n",
    "        data (pd.DataFrame): The dataframe containing the model variables.\n",
    "\n",
    "    Returns:\n",
    "        arviz.InferenceData: The fitted model object containing posterior samples.\n",
    "    \"\"\"\n",
    "    # 1. Prepare coordinates for random effects, if they exist in the formula\n",
    "    coords = {}\n",
    "    if '(1|ID)' in formula:\n",
    "        fixed_formula = formula.split('(1|ID)')[0].strip().rstrip('+').strip()\n",
    "        has_re = True\n",
    "        id_idx, id_cats = pd.factorize(data['ID'])\n",
    "        coords['ID_dim'] = id_cats\n",
    "    else:\n",
    "        fixed_formula = formula\n",
    "        has_re = False\n",
    "\n",
    "    # 2. Use patsy to create design matrices for the fixed effects\n",
    "    y_patsy, X_patsy = patsy.dmatrices(fixed_formula, data=data)\n",
    "    y_data = np.asarray(y_patsy).ravel()\n",
    "    X_data = np.asarray(X_patsy)\n",
    "    X_cols = X_patsy.design_info.column_names\n",
    "\n",
    "    # 3. Construct the PyMC model\n",
    "    with pm.Model(coords=coords) as model:\n",
    "        # --- Priors (matching the R brms setup) ---\n",
    "        intercept = pm.Normal('Intercept', mu=0, sigma=100)\n",
    "        slopes = pm.Cauchy('slopes', alpha=0, beta=2.5, shape=X_data.shape[1] - 1)\n",
    "        betas = pm.math.concatenate([[intercept], slopes])\n",
    "        \n",
    "        # Priors for random effects (if any)\n",
    "        if has_re:\n",
    "            sigma_id = pm.HalfCauchy('sigma_id', beta=2.5)\n",
    "            z_id = pm.Normal('z_id', mu=0, sigma=1, dims='ID_dim')\n",
    "            intercept_id = pm.Deterministic('intercept_id', z_id * sigma_id, dims='ID_dim')\n",
    "        \n",
    "        # CHANGED: Renamed 'phi' to 'nu' to match PyMC's parameterization.\n",
    "        nu = pm.HalfNormal('nu', sigma=100)\n",
    "\n",
    "        # --- Linear Model (eta) ---\n",
    "        eta = pm.math.dot(X_data, betas)\n",
    "        if has_re:\n",
    "            eta += intercept_id[id_idx]\n",
    "\n",
    "        # --- Likelihood ---\n",
    "        # Transform eta to the (0, 1) scale for the mean of the Beta distribution\n",
    "        mu = pm.math.invlogit(eta)\n",
    "        \n",
    "        # CHANGED: Used 'nu' instead of 'phi' in the pm.Beta call.\n",
    "        pm.Beta(y_patsy.design_info.column_names[0], mu=mu, nu=nu, observed=y_data)\n",
    "        \n",
    "        # --- Sampling from the Posterior ---\n",
    "        idata = pm.sample(draws=2000, tune=2000, chains=4, cores=4, progressbar=False, target_accept=0.95)\n",
    "        \n",
    "        # Rename slope variables for a cleaner summary table\n",
    "        idata.posterior = idata.posterior.rename_vars(\n",
    "            {'slopes': [col for col in X_cols if col != 'Intercept']}\n",
    "        )\n",
    "    return idata\n",
    "\n",
    "\n",
    "def pymc_summary(idata, var_names=None):\n",
    "    \"\"\"\n",
    "    Creates a formatted summary table from a fitted PyMC model.\n",
    "\n",
    "    Args:\n",
    "        idata (arviz.InferenceData): The fitted model object.\n",
    "        var_names (list, optional): A list of variable names to include in the summary.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A formatted summary table with posterior estimates and diagnostics.\n",
    "    \"\"\"\n",
    "    if var_names is None:\n",
    "        # Auto-detect fixed-effect variable names\n",
    "        var_names = [v for v in idata.posterior.data_vars if 'z_id' not in v and 'sigma_id' not in v and 'intercept_id' not in v]\n",
    "\n",
    "    summary = az.summary(idata, var_names=var_names, kind='stats', hdi_prob=0.95)\n",
    "    posterior = az.extract(idata, var_names=var_names)\n",
    "    \n",
    "    # Calculate Probability of Direction (pd)\n",
    "    pd_values = {}\n",
    "    for var in posterior.data_vars:\n",
    "        samples = posterior[var].values.flatten()\n",
    "        pd_val = np.mean(samples > 0)\n",
    "        pd_val = max(pd_val, 1 - pd_val)\n",
    "        pd_values[var] = pd_val\n",
    "        \n",
    "    summary['pd'] = summary.index.map(pd_values).round(3)\n",
    "    # Add a significance flag based on pd\n",
    "    summary['signif'] = np.where(summary['pd'] >= 0.975, '*', ' ')\n",
    "    summary = summary[['mean', 'sd', 'pd', 'signif']]\n",
    "    summary.columns = ['Est.', '(SE)', 'pd', '']\n",
    "    summary['Est.(SE)'] = summary.apply(lambda row: f\"{row['Est.']:.3f} ({row['(SE)']:.3f})\", axis=1)\n",
    "    \n",
    "    return summary[['Est.(SE)', 'pd', '']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77f059a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Data Loading and Processing ---\n",
    "\n",
    "# --- Load Raw Data ---\n",
    "# The original dataset contains data from multiple studies.\n",
    "Samp = pd.read_csv(\"Lifespan.csv\", index_col=0) \n",
    "\n",
    "# --- Initial Filtering and Cleaning (to match R script) ---\n",
    "# This chain filters to the final sample (N = 594) used in the paper.\n",
    "Disc_Raw = Samp[\n",
    "    (Samp['type'] == 'delay') & (Samp['task'] == 'loss') &\n",
    "    (Samp['age'].notna()) & (Samp['age'].between(20, 80)) &\n",
    "    (Samp['check'] == 6) & (Samp['sex'].notna()) &\n",
    "    ((Samp['age'] - 10 * Samp['age_grp']).between(0, 10)) # Removes inconsistent age reporting\n",
    "].copy()\n",
    "\n",
    "# --- Feature Engineering and Renaming ---\n",
    "# Create Age_Group factor for plotting and descriptive statistics\n",
    "age_bins = [19, 34, 50, 64, 80]\n",
    "age_labels = [\"20-34\", \"35-50\", \"51-64\", \"65-80\"]\n",
    "Disc_Raw['age_grp_factor'] = pd.cut(Disc_Raw['age'], bins=age_bins, labels=age_labels)\n",
    "\n",
    "# Rename columns for clarity and consistency with the paper\n",
    "rename_dict = {\n",
    "    'type': 'Exp', 'id': 'ID', 'amt': 'Amount', 'iv': 'Delay', 'value': 'SV', 'age': 'Age',\n",
    "    'income': 'Income', 'sex': 'Gender', 'depress': 'Depression', 'anxious': 'Anxiety',\n",
    "    'hads': 'Distress', 'edu': 'Education', 'health': 'Health', 'age_grp_factor': 'Age_Group',\n",
    "    'eth': 'Ethnicity', 'race': 'Race'\n",
    "}\n",
    "Disc_Raw = Disc_Raw.rename(columns=rename_dict).filter(items=rename_dict.values())\n",
    "\n",
    "# --- Create Group-Level Dataframe for Plotting (Figure 1) ---\n",
    "Disc_Grp = Disc_Raw.copy()\n",
    "Disc_Grp['Amount_cat'] = pd.Categorical(\n",
    "    Disc_Grp['Amount'].replace({1: \"$150\", 2: \"$2,500\", 3: \"$30,000\"}),\n",
    "    categories=[\"$150\", \"$2,500\", \"$30,000\"], ordered=True\n",
    ")\n",
    "Disc_Grp = Disc_Grp.groupby(['Age_Group', 'Amount_cat', 'Delay'], observed=True).agg(Mean_SV=('SV', 'mean')).reset_index()\n",
    "\n",
    "# --- Calculate Area under the Curve (AuC) for Each Individual ---\n",
    "# AuC is the primary dependent variable, calculated for each participant at each loss amount.\n",
    "AuC_ID = Disc_Raw.sort_values('Delay').groupby(['ID', 'Amount']).apply(\n",
    "    lambda g: calculate_auc(g['Delay'] / g['Delay'].max(), g['SV'])\n",
    ").reset_index(name='AuC')\n",
    "\n",
    "# Join back the unique demographic information for each participant\n",
    "demographics = Disc_Raw.drop_duplicates(subset='ID').drop(columns=['Amount', 'Delay', 'SV', 'Exp'])\n",
    "AuC_ID = pd.merge(AuC_ID, demographics, on='ID', how='left')\n",
    "\n",
    "# Remap Education from codes to years\n",
    "edu_map = {1: 5, 2: 12, 3: 14, 4: 16, 5: 18}\n",
    "AuC_ID['Education'] = AuC_ID['Education'].map(edu_map)\n",
    "\n",
    "# --- Create Model-Specific Dataframes with Scaled Predictors ---\n",
    "# Predictors are scaled by subtracting the mean and dividing by 2*SD for model stability and interpretability.\n",
    "def scale_var(series):\n",
    "    return (series - series.mean()) / (2 * series.std())\n",
    "\n",
    "# Data for participants aged 35+\n",
    "DL_dat1 = AuC_ID[AuC_ID['Age'] >= 35].copy()\n",
    "DL_dat1['Age_std'] = scale_var(DL_dat1['Age'])\n",
    "\n",
    "# Data for model with Income\n",
    "DL_dat2 = AuC_ID[(AuC_ID['Age'] >= 35) & AuC_ID['Income'].notna()].copy()\n",
    "for col in ['Age', 'Income']:\n",
    "    DL_dat2[f'{col}_std'] = scale_var(DL_dat2[col])\n",
    "\n",
    "# Data for models with psychological distress measures\n",
    "DL_dat3 = AuC_ID[(AuC_ID['Age'] >= 35) & AuC_ID['Income'].notna() & AuC_ID['Distress'].notna()].copy()\n",
    "for col in ['Age', 'Income', 'Anxiety', 'Depression', 'Distress']:\n",
    "    DL_dat3[f'{col}_std'] = scale_var(DL_dat3[col])\n",
    "\n",
    "# Data for the full model (Model 4)\n",
    "DL_dat4 = AuC_ID[\n",
    "    (AuC_ID['Age'] >= 35) & AuC_ID['Income'].notna() & AuC_ID['Gender'].notna() & \n",
    "    AuC_ID['Education'].notna() & AuC_ID['Distress'].notna() & AuC_ID['Health'].notna()\n",
    "].copy()\n",
    "for col in ['Age', 'Amount', 'Income', 'Education', 'Anxiety', 'Depression', 'Distress', 'Health']:\n",
    "    DL_dat4[f'{col}_std'] = scale_var(DL_dat4[col])\n",
    "DL_dat4['Gender_c'] = DL_dat4['Gender'] - DL_dat4['Gender'].mean() # Center binary predictor\n",
    "\n",
    "# Clip AuC values for Beta regression, which requires the outcome to be in the open interval (0, 1)\n",
    "for df in [DL_dat1, DL_dat2, DL_dat3, DL_dat4]:\n",
    "    df['AuC'] = np.clip(df['AuC'], 1e-5, 1 - 1e-5)\n",
    "\n",
    "print(f\"Data processing complete. Final sample size: {AuC_ID['ID'].nunique()} participants.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39eee1a",
   "metadata": {},
   "source": [
    "## Descriptive & Correlational Analyses\n",
    "\n",
    "This section replicates the descriptive results from the paper, including the visualization of group-level discounting functions (Figure 1), goodness-of-fit statistics for the hyperboloid model, reliability of the AuC measure, and the correlation matrices for key variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0e02c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. DESCRIPTIVE ANALYSES ---\n",
    "\n",
    "# --- Figure 1 Replication: Group-Level Discounting Functions ---\n",
    "def hyperboloid(delay, k, s):\n",
    "    \"\"\"Mathematical function for hyperboloid discounting.\"\"\"\n",
    "    return 1 / (1 + k * delay)**s\n",
    "\n",
    "# --- Goodness-of-Fit for Group-Level Hyperboloid Functions ---\n",
    "print(\"\\n--- R-squared for Group-Level Hyperboloid Fits ---\")\n",
    "r2_results = Disc_Grp.groupby(['Age_Group', 'Amount_cat'], observed=True).apply(\n",
    "    lambda grp: r2_score(grp['Mean_SV'], hyperboloid(grp['Delay'], *curve_fit(hyperboloid, grp['Delay'], grp['Mean_SV'], p0=[0.1, 1])[0]))\n",
    ").unstack()\n",
    "print(r2_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee34aae6",
   "metadata": {},
   "source": [
    "### Reliability and Correlational Analyses\n",
    "\n",
    "This section assesses the internal consistency of the Area under the Curve (AuC) measure across the three different loss amounts. It also replicates the correlation matrices from the paper for both the full sample (ages 20-80) and the primary analysis sample (ages 35-80)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c411316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Reliability of AuC Measure (Cronbach's Alpha) ---\n",
    "print(\"--- Reliability of AuC Measure (Cronbach's Alpha) ---\")\n",
    "reliability_df = AuC_ID.pivot(index='ID', columns='Amount', values='AuC')\n",
    "print(pg.cronbach_alpha(data=reliability_df))\n",
    "\n",
    "# --- Correlation Matrix for All Participants (Aged 20-80) ---\n",
    "print(\"\\n--- Correlation Matrix for All Participants (Aged 20-80) ---\")\n",
    "Cor_df_full = AuC_ID.groupby('ID').agg(\n",
    "    Age=('Age', 'mean'), Income=('Income', 'mean'), Education=('Education', 'mean'),\n",
    "    Gender=('Gender', 'mean'), Distress=('Distress', 'mean'), Anxiety=('Anxiety', 'mean'),\n",
    "    Depression=('Depression', 'mean'), Health=('Health', 'mean'), AuC=('AuC', 'mean')\n",
    ")\n",
    "print(Cor_df_full.corr(method='pearson').round(3))\n",
    "\n",
    "# --- Correlation Matrix for Participants Aged 35-80 (Table 2 Replication) ---\n",
    "print(\"\\n--- Correlation Matrix for Participants Aged 35-80 ---\")\n",
    "Cor_df_35plus = AuC_ID[AuC_ID['Age'] >= 35].groupby('ID').agg(\n",
    "    Age=('Age', 'mean'), Income=('Income', 'mean'), Education=('Education', 'mean'),\n",
    "    Gender=('Gender', 'mean'), Distress=('Distress', 'mean'), Anxiety=('Anxiety', 'mean'),\n",
    "    Depression=('Depression', 'mean'), Health=('Health', 'mean'), AuC=('AuC', 'mean')\n",
    ")\n",
    "print(Cor_df_35plus.corr(method='pearson').round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89d6ebe",
   "metadata": {},
   "source": [
    "## Hypothesis Testing: Bayesian Multilevel Models\n",
    "\n",
    "This section replicates the main hypothesis tests from the paper, corresponding to Table 3. A series of four Bayesian multilevel beta regression models are fitted to test the effects of age, income, anxiety, and other covariates on AuC for participants aged 35 and older."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de59e4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. HYPOTHESIS TESTING: MAIN MODELS ---\n",
    "\n",
    "# --- Model 1: AuC ~ Age + Age^2 ---\n",
    "# Tests for a linear and quadratic effect of age on discounting.\n",
    "print(\"--- Model 1: AuC ~ Age + Age^2 ---\")\n",
    "idata_mod1b = betaMLM_pymc(\"AuC ~ Age_std + I(Age_std**2) + (1|ID)\", DL_dat1)\n",
    "print(pymc_summary(idata_mod1b))\n",
    "\n",
    "# --- Model 2: AuC ~ Age + Age^2 + Income ---\n",
    "# Adds income as a predictor.\n",
    "print(\"\\n--- Model 2: AuC ~ Age + Age^2 + Income ---\")\n",
    "idata_mod2 = betaMLM_pymc(\"AuC ~ Age_std + I(Age_std**2) + Income_std + (1|ID)\", DL_dat2)\n",
    "print(pymc_summary(idata_mod2))\n",
    "\n",
    "# --- Model 3: AuC ~ Age + Age^2 + Income + Anxiety ---\n",
    "# Adds anxiety as a predictor.\n",
    "print(\"\\n--- Model 3: AuC ~ Age + Age^2 + Income + Anxiety ---\")\n",
    "idata_mod3 = betaMLM_pymc(\"AuC ~ Age_std + I(Age_std**2) + Income_std + Anxiety_std + (1|ID)\", DL_dat3)\n",
    "print(pymc_summary(idata_mod3))\n",
    "\n",
    "# --- Model 4: Full Model with Covariates and Age Interactions ---\n",
    "# The full model includes all covariates and their interactions with age.\n",
    "print(\"\\n--- Model 4: Full Model with Covariates and Age Interactions ---\")\n",
    "formula_mod4 = (\"AuC ~ (Age_std+Income_std + Anxiety_std + Amount_std + Education_std + Gender_c + Health_std)^2 + I(Age_std^2) + (1 + Amount_std|ID))\")\n",
    "idata_mod4 = betaMLM_pymc(formula_mod4, DL_dat4)\n",
    "print(pymc_summary(idata_mod4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c11d67",
   "metadata": {},
   "source": [
    "## Supplementary Analyses: Depression and Distress Models\n",
    "\n",
    "The paper notes that while anxiety was a significant predictor of discounting, depression and overall psychological distress were not (when controlling for age and income). This section presents the models that confirm these findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f72354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. SUPPLEMENTARY ANALYSES: DEPRESSION & DISTRESS ---\n",
    "\n",
    "# --- Model S1: Test effect of Depression ---\n",
    "print(\"--- Model S1: AuC ~ Age + Age^2 + Income + Depression ---\")\n",
    "idata_modS1 = betaMLM_pymc(\"AuC ~ Age_std + I(Age_std**2) + Income_std + Depression_std + (1|ID)\", DL_dat3)\n",
    "print(pymc_summary(idata_modS1, ['Intercept', 'Age_std', 'I(Age_std ** 2)', 'Income_std', 'Depression_std']))\n",
    "\n",
    "# --- Model S3: Test effect of Distress ---\n",
    "print(\"\\n--- Model S3: AuC ~ Age + Age^2 + Income + Distress ---\\n\")\n",
    "idata_modS3 = betaMLM_pymc(\"AuC ~ Age_std + I(Age_std**2) + Income_std + Distress_std + (1|ID)\", DL_dat3)\n",
    "print(pymc_summary(idata_modS3, ['Intercept', 'Age_std', 'I(Age_std ** 2)', 'Income_std', 'Distress_std']))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
